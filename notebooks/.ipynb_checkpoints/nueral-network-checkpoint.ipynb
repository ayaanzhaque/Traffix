{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nueral Network\n",
    "This is another model we are testing for our application. A nueral network may perform better than an XG Boost model, so we will load the same data and see if we can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tf imports\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow_addons.optimizers import RectifiedAdam, Lookahead\n",
    "from sklearn.base import BaseEstimator\n",
    "from tensorflow_addons.activations import gelu\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, OrdinalEncoder, FunctionTransformer, QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(X, Y=None):\n",
    "    X['IntersectionId'] = X['IntersectionId'].astype('str') + X['City']\n",
    "    X['city_month'] = X[\"City\"] + X[\"Month\"].astype(str)\n",
    "    # Creating a new column by mapping the city_month variable to it's corresponding average monthly temperature\n",
    "    X[\"average_temp\"] = X['city_month'].map(monthly_av)\n",
    "    # Creating a new column by mapping the city_month variable to it's corresponding average monthly rainfall\n",
    "    X[\"average_rainfall\"] = X['city_month'].map(monthly_rainfall)\n",
    "    # Creating a new column by mapping the city_month variable to it's corresponding average monthly snowfall\n",
    "    X[\"average_snowfall\"] = X['city_month'].map(monthly_snowfall)\n",
    "    # Creating a new column by mapping the city_month variable to it's corresponding average monthly daylight\n",
    "    X[\"average_daylight\"] = X['city_month'].map(monthly_daylight)\n",
    "    # Creating a new column by mapping the city_month variable to it's corresponding average monthly sunshine\n",
    "    X[\"average_sunshine\"] = X['city_month'].map(monthly_sunshine)\n",
    "    \n",
    "    \n",
    "    X[\"Center_Latitude\"] = X['City'].map(center_latitude)\n",
    "    X[\"Center_Longitude\"] = X['City'].map(center_longitude)\n",
    "    X[\"CenterDistance\"] = np.sqrt((X['Latitude'] - X[\"Center_Latitude\"]) ** 2 + (X['Center_Longitude'] - X[\"Longitude\"]) ** 2)\n",
    "    \n",
    "    X['SameStreet'] = X['EntryStreetName'] ==  X['ExitStreetName']\n",
    "    X['SameHeading'] = X['EntryHeading'] ==  X['ExitHeading']\n",
    "    X['Vector'] = X['EntryHeading'] + X['ExitHeading']\n",
    "    X['Hour_x'] = np.cos(X['Hour'] * np.pi/12.)\n",
    "    X['Hour_y'] = np.sin(X['Hour'] * np.pi/12.)\n",
    "    X['Month_x'] = np.cos(X['Month'] * np.pi/6.)\n",
    "    X['Month_y'] = np.sin(X['Month'] * np.pi/6.)\n",
    "    X['is_day'] = 0\n",
    "    X.iloc[X[(X['Hour'] > 5) & (X['Hour'] < 20)].index, X.columns.get_loc('is_day')] = 1 \n",
    "    \n",
    "    for street_dir in ['Entry', 'Exit']:\n",
    "        data = np.char.lower(X[street_dir + 'Heading'].values.astype('str'))\n",
    "        # N => Y +1\n",
    "        # S => Y -1\n",
    "        # E => X +1\n",
    "        # W => X -1\n",
    "        X['NS_' + street_dir] = np.where(np.char.rfind(data, 'N') > -1, 1, 0)\n",
    "        X['NS_' + street_dir] = np.where(np.char.rfind(data, 'S') > -1, -1, X['NS_' + street_dir].values)\n",
    "        X['EW_' + street_dir] = np.where(np.char.rfind(data, 'E') > -1, 1, 0)\n",
    "        X['EW_' + street_dir] = np.where(np.char.rfind(data, 'W') > -1, -1, X['EW_' + street_dir].values)\n",
    "        X[street_dir + '_Angle'] = X[street_dir + 'Heading'].map(directions)\n",
    "\n",
    "    X['Angle'] = X['Exit_Angle'] - X['Entry_Angle'] \n",
    "    X['x_Angle'] = np.cos(X['Angle'].values)\n",
    "    X['y_Angle'] = np.sin(X['Angle'].values)\n",
    "\n",
    "    X['NS'] = X['NS_Exit'] - X['NS_Entry'] \n",
    "    X['EW'] = X['EW_Exit'] - X['EW_Entry']\n",
    "    \n",
    "    for street_dir in ['Entry', 'Exit']:\n",
    "        data = np.char.lower(X[street_dir + 'StreetName'].values.astype('str'))\n",
    "        for type_cat in ['road', 'way', 'street', 'avenue', 'boulevard', 'lane', 'drive', 'terrace', 'place', 'court', 'plaza', 'square']:\n",
    "            X['Is' + street_dir + type_cat] = np.char.rfind(data, type_cat) > -1\n",
    "            \n",
    "    #X = X.drop(columns=['IntersectionId', 'Center_Latitude', 'Center_Longitude', 'city_month', 'Latitude', 'Longitude', 'CenterDistance' ])\n",
    "    #X = X.drop(columns=['EntryStreetName', 'ExitStreetName' ])\n",
    "\n",
    "    road_type = []\n",
    "    for street_dir in ['Entry', 'Exit']:\n",
    "        for type_cat in ['road', 'way', 'street', 'avenue', 'boulevard', 'lane', 'drive', 'terrace', 'place', 'court', 'plaza', 'square']:\n",
    "            road_type.append('Is' + street_dir + type_cat)\n",
    "    \n",
    "    return X[[\n",
    "        'CenterDistance',\n",
    "        'EntryHeading',\n",
    "        'ExitHeading',\n",
    "        'NS_Entry',\n",
    "        'EW_Entry',\n",
    "        'NS_Exit',\n",
    "        'EW_Exit',\n",
    "        'Entry_Angle',\n",
    "        'Exit_Angle',\n",
    "        'NS',\n",
    "        'EW',\n",
    "        'Angle',\n",
    "        'x_Angle',\n",
    "        'y_Angle',\n",
    "        'is_day',\n",
    "        'SameStreet',\n",
    "        'SameHeading',\n",
    "        'Vector',\n",
    "        'Hour_x',\n",
    "        'Hour_y',\n",
    "        'Month_x',\n",
    "        'Month_y',\n",
    "        'City',\n",
    "        'average_temp',\n",
    "        'average_rainfall',\n",
    "        'average_snowfall',\n",
    "        'average_daylight',\n",
    "        'average_sunshine',\n",
    "        *road_type\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(grid_params, in_dim, out_dim, patience=20, loss='rmse', activation='sigmoid'):\n",
    "    \n",
    "    mul_input = grid_params['mul_input']\n",
    "    n_layer = grid_params['n_layer']\n",
    "    \n",
    "    first_layer_size = int(in_dim*mul_input)\n",
    "    hidden_layers = []\n",
    "    for i_layer in range(n_layer, 0, -1):\n",
    "        layer_size = int(((first_layer_size - out_dim) / n_layer) * i_layer + out_dim)\n",
    "        hidden_layers.append(layer_size)\n",
    "\n",
    "    print(\"Input dim:\" + str(in_dim))\n",
    "    print(\"Hidden Layers:\" + str(hidden_layers))\n",
    "    print(\"Output dim:\" + str(out_dim))\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(in_dim,input_shape=[in_dim],activation=gelu))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(.5))\n",
    "    \n",
    "    for layer in hidden_layers:\n",
    "        model.add(Dense(layer,activation=gelu))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Dropout(.5))\n",
    "    \n",
    "    model.add(Dense(out_dim, activation=activation))\n",
    "    \n",
    "    radam = RectifiedAdam()\n",
    "    ranger = Lookahead(radam, sync_period=6, slow_step_size=0.5)\n",
    "    optimizer = ranger#Adam(learning_rate=0.001)\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience, restore_best_weights=True)\n",
    "    es.set_model(model)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=[loss], metrics=[])\n",
    "    \n",
    "    return model, [ es ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasModel(BaseEstimator):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_layer=1, \n",
    "        mul_input=1.75, \n",
    "        patience=5,\n",
    "        batch_size=32,\n",
    "        loss='msle',\n",
    "        activation='sigmoid'\n",
    "        ):\n",
    "        self._estimator_type = 'reg' \n",
    "        self.n_layer = n_layer\n",
    "        self.mul_input = mul_input\n",
    "        self.patience = patience\n",
    "        self.loss = loss\n",
    "        self.activation = activation\n",
    "        self.batch_size = batch_size\n",
    "        #self.__name__ = self._wrapped_obj.__class__.__name__ + \"PredictWrapper\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        if not hasattr(self, 'model'):\n",
    "            return \"Empty\"\n",
    "        return self.model.__repr__()\n",
    "\n",
    "    def __str__(self):\n",
    "        if not hasattr(self, 'model'):\n",
    "            return \"Empty\"\n",
    "        return self.model.__str__()\n",
    "        \n",
    "    def fit(self, X, Y, x_val, y_val):\n",
    "        model, cbs = create_model(\n",
    "            self.get_params(),\n",
    "            X.shape[1],\n",
    "            Y.shape[0],\n",
    "            patience=self.patience,\n",
    "            loss=self.loss,\n",
    "            activation=self.activation\n",
    "        )\n",
    "#         X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle=True)\n",
    "        self.model = model\n",
    "        self.model.fit(X_train,y_train, batch_size=self.batch_size,epochs=10000, validation_data=[X_val,y_val], verbose=2, callbacks=cbs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, *args, **kwargs):\n",
    "        return self.model.predict(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasModel(n_layer=3, mul_input=8, batch_size=1024, patience=10, activation=None, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DistanceToFirstStop_p20', 'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50', 'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80', 'TimeFromFirstStop_p20', 'TimeFromFirstStop_p40', 'TimeFromFirstStop_p50', 'TimeFromFirstStop_p60', 'TimeFromFirstStop_p80', 'TotalTimeStopped_p20', 'TotalTimeStopped_p40', 'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80']\n",
      "35\n",
      "['City', 'EntryHeading', 'EntryStreetName', 'ExitHeading', 'ExitStreetName', 'Hour', 'Istrain', 'Latitude', 'Longitude', 'Month', 'Weekend', 'Latitude3', 'Longitude3', 'EntryStreetMissing', 'ExitStreetMissing', 'CMWH', 'DiffHeading', 'Rainfall', 'Temperature', 'EntryType', 'ExitType', 'Intersection', 'SameStreet', 'LatitudeDist', 'LongitudeDist', 'CenterDistL1', 'CenterDistL2', 'Longitude3Count', 'Latitude3Count', 'ExitStreetNameCount', 'EntryStreetNameCount', 'IntersectionCount', 'Longitude3UniqueIntersections', 'Latitude3UniqueIntersections', 'ExitStreetNameUniqueIntersections']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "full = pd.read_csv('./data/features_v3.csv.gz')\n",
    "full.head()\n",
    "\n",
    "full['random'] = np.random.rand(len(full))\n",
    "\n",
    "TRAIN_SAMPLE_SIZE = 0.75\n",
    "\n",
    "train = full[full.Istrain == 1]\n",
    "test = full[full.Istrain == 0]\n",
    "\n",
    "column_stats = pd.concat([\n",
    "    pd.DataFrame(full.count()).rename(columns={0: 'cnt'}),\n",
    "    pd.DataFrame(full.nunique()).rename(columns={0: 'unique'}),\n",
    "], sort=True, axis=1)\n",
    "column_stats.sort_values(by='unique')\n",
    "\n",
    "train_columns = list(column_stats[column_stats.cnt < 10 ** 6].index)\n",
    "print(train_columns)\n",
    "\n",
    "target_columns = [\n",
    "    'TotalTimeStopped_p20',\n",
    "    'TotalTimeStopped_p50',\n",
    "    'TotalTimeStopped_p80',\n",
    "    'DistanceToFirstStop_p20',\n",
    "    'DistanceToFirstStop_p50',\n",
    "    'DistanceToFirstStop_p80',\n",
    "]\n",
    "\n",
    "do_not_use = train_columns + ['IsTrain', 'Path', 'RowId', 'IntersectionId',\n",
    "                              'random', 'intersection_random', 'ValidationGroup']\n",
    "\n",
    "feature_columns = [c for c in full.columns if c not in do_not_use]\n",
    "print(len(feature_columns))\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting for target TotalTimeStopped_p20\n",
      "(642086, 35) (642086,) (214301, 35) (214301,)\n",
      "Input dim:35\n",
      "Hidden Layers:[280, 214215, 428150]\n",
      "Output dim:642086\n"
     ]
    }
   ],
   "source": [
    "for i, target in enumerate(target_columns):\n",
    "    print(f'Training and predicting for target {target}')\n",
    "    train_idx = train.random < TRAIN_SAMPLE_SIZE\n",
    "    valid_idx = train.random >= TRAIN_SAMPLE_SIZE\n",
    "\n",
    "    Xtr = train[train_idx][feature_columns]\n",
    "    Xv = train[valid_idx][feature_columns]\n",
    "    ytr = train[train_idx][target].values\n",
    "    yv = train[valid_idx][target].values\n",
    "    print(Xtr.shape, ytr.shape, Xv.shape, yv.shape)\n",
    "\n",
    "    mc = ModelCheckpoint('.models/nn.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    \n",
    "    history = model.fit(Xtr, ytr, Xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = pipeline.predict(X_test)\n",
    "res_df = pd.DataFrame(data=Y_test, columns=targets)\n",
    "res_df['RowId'] = X_test['RowId']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
